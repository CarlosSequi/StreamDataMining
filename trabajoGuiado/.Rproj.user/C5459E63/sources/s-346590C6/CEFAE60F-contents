---
title: "StreamDataMining"
author: "Carlos Manuel Sequí Sánchez"
date: "24 de abril de 2019"
output: pdf_document
---

\section{EJERCICIO 1 (clasificación). Se pide comparar la eficacia de un Hoeffding Tree con un clasificador Naïve Bayes, para un flujo de datos de 1.000.000 de instancias generadas con un generador RandomTreeGenerator, suponiendo una frecuencia de muestreo de 10.000 y con el método de evaluación Interleaved Test-Then-Train.} 

Una ejecución para Naïve Bayes:	  
		\textbf{java -cp moa.jar -javaagent:sizeofag.jar moa.DoTask "EvaluateInterleavedTestThenTrain -l bayes.NaiveBayes -s generators.RandomTreeGenerator -i 1000000 -f 10000"}


Una ejecución para Hoeffding Trees:  
		\textbf{java -cp moa.jar -javaagent:sizeofag.jar moa.DoTask "EvaluateInterleavedTestThenTrain -l trees.HoeffdingTree -s generators.RandomTreeGenerator -i 1000000 -f 10000"}

Para saber si hay diferencias significativas, tendríamos que generar una población de resultados y escoger una medida de eficacia para comparar.
Para ello, escogeremos 30 semillas diferentes y ejecutaremos 30 veces el mismo método (en total 30 ejecuciones para Naïve Bayes y otras 30 para Hoeffding Trees). Escogeremos los resultados del porcentaje de aciertos en la clasificación, y las compararemos con un test estadístico.  

A continuación una imagen del script creado para generación de la población de 30 instancias de distintas semillas con Naïve Bayes (he procedido de la misma forma para la creación de la población de Hoeffding Trees)

\includegraphics{scriptNaives}

Una vez generados los ficheros de datos, procedemos a crear las poblaciones en si


Leemos los datos de Naïves Bayes y creamos su población a partir de los fichers .csv
```{r}
datosNaives = array(dim = 30)
for (i in 1:30)
{
  nombreFichero = paste(c(paste(c("./datosNaiveBayes/nb",i),collapse = ""),".csv"),collapse="")
  nuevoFichero = read.csv(nombreFichero)
  nuevoDato = nuevoFichero$classifications.correct..percent.[length(nuevoFichero$classifications.correct..percent.)]
  datosNaives[i] = nuevoDato
}
```

Leemos los datos de Hoeffding trees y creamos su población a partir de los fichers .csv
```{r}
datosHoeffding = array(dim = 30)
for (i in 1:30)
{
  nombreFichero = paste(c(paste(c("./datosHoeffdingTrees/HF",i),collapse = ""),".csv"),collapse="")
  nuevoFichero = read.csv(nombreFichero)
  nuevoDato = nuevoFichero$classifications.correct..percent.[length(nuevoFichero$classifications.correct..percent.)]
  datosHoeffding[i] = nuevoDato
}
```


Una vez generadas las poblaciones, comprobamos la distribución de ambas para conocer que tipo de test utilizar.  


Comprobamos si los datos de Naive Bayes siguen una distribución normal con el test de Saphiro Wilk y un histograma de los datos
```{r}
shapiro.test(datosNaives)
hist(datosNaives, col="blue", prob=T,ylim=c(0,13), xlim=c(73.5,73.85)) 
lines(density(datosNaives))
```

Comprobamos si los datos de Hoeffding siguen una distribución normal con el test de Saphiro Wilk y un histograma de los datos
```{r}
shapiro.test(datosHoeffding)
hist(datosHoeffding, col="blue") 
lines(density(datosHoeffding))
```

Como vemos ambos conjuntos de datos siguen una distribución normal. Debido a esto, vamos a utilizar un t-test con el fin de evidenciar si existen o no diferencias significativas entre las medias de ambos grupos.
```{r}
t.test(datosNaives,datosHoeffding)
```

Tal como observamos, al ser el p-value inferior a 0.05, podemos decir con alta certeza que las medias de las dos poblaciones de datos difiere de manera significativa. Por esta misma razón, el mejor de los algoritmos que han generado estos grupos de datos es el que mejor porcentaje de aciertos promedio ha proporcionado, es decir, el algoritmo Hoeffding Trees.

\section{EJERCICIO 2 (Concept Drift).}